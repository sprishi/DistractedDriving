{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "c0_files = os.listdir(\"driver/c0\")\n",
    "c1_files = os.listdir(\"driver/c1\")\n",
    "c2_files = os.listdir(\"driver/c2\")\n",
    "c3_files = os.listdir(\"driver/c3\")\n",
    "c4_files = os.listdir(\"driver/c4\")\n",
    "c5_files = os.listdir(\"driver/c5\")\n",
    "c6_files = os.listdir(\"driver/c6\")\n",
    "c7_files = os.listdir(\"driver/c7\")\n",
    "c8_files = os.listdir(\"driver/c8\")\n",
    "c9_files = os.listdir(\"driver/c9\")\n",
    "\n",
    "\n",
    "c0 = len(c0_files)\n",
    "c1 = len(c1_files)\n",
    "c2 = len(c2_files)\n",
    "c3 = len(c3_files)\n",
    "c4 = len(c4_files)\n",
    "c5 = len(c5_files)\n",
    "c6 = len(c6_files)\n",
    "c7 = len(c7_files)\n",
    "c8 = len(c8_files)\n",
    "c9 = len(c9_files)\n",
    "\n",
    "\n",
    "c0_train = int(c0 * 0.8)\n",
    "c0_test = c0 - c0_train\n",
    "\n",
    "c1_train = int(c1 * 0.8)\n",
    "c0_test = c1 - c1_train\n",
    "\n",
    "c2_train = int(c2 * 0.8)\n",
    "c2_test = c2 - c2_train\n",
    "\n",
    "c3_train = int(c3 * 0.8)\n",
    "c3_test = c3 - c3_train\n",
    "\n",
    "c4_train = int(c4 * 0.8)\n",
    "c4_test = c4 - c4_train\n",
    "\n",
    "c5_train = int(c5 * 0.8)\n",
    "c5_test = c5 - c5_train\n",
    "\n",
    "c6_train = int(c6 * 0.8)\n",
    "c6_test = c6 - c6_train\n",
    "\n",
    "c7_train = int(c7 * 0.8)\n",
    "c7_test = c7 - c7_train\n",
    "\n",
    "c8_train = int(c8 * 0.8)\n",
    "c8_test = c8 - c8_train\n",
    "\n",
    "c9_train = int(c9 * 0.8)\n",
    "c9_test = c9 - c9_train\n",
    "\n",
    "'''\n",
    "os.makedirs('driver_data_prepared/train/c0')\n",
    "os.makedirs('driver_data_prepared/train/c1')\n",
    "os.makedirs('driver_data_prepared/train/c2')\n",
    "os.makedirs('driver_data_prepared/train/c3')\n",
    "os.makedirs('driver_data_prepared/train/c4')\n",
    "os.makedirs('driver_data_prepared/train/c5')\n",
    "os.makedirs('driver_data_prepared/train/c6')\n",
    "os.makedirs('driver_data_prepared/train/c7')\n",
    "os.makedirs('driver_data_prepared/train/c8')\n",
    "os.makedirs('driver_data_prepared/train/c9')\n",
    "\n",
    "os.makedirs('driver_data_prepared/test/c0')\n",
    "os.makedirs('driver_data_prepared/test/c1')\n",
    "os.makedirs('driver_data_prepared/test/c2')\n",
    "os.makedirs('driver_data_prepared/test/c3')\n",
    "os.makedirs('driver_data_prepared/test/c4')\n",
    "os.makedirs('driver_data_prepared/test/c5')\n",
    "os.makedirs('driver_data_prepared/test/c6')\n",
    "os.makedirs('driver_data_prepared/test/c7')\n",
    "os.makedirs('driver_data_prepared/test/c8')\n",
    "os.makedirs('driver_data_prepared/test/c9')\n",
    "'''\n",
    "\n",
    "'''\n",
    "for i in range(0, c0_train):\n",
    "    file = \"driver/c0/\" + c0_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c0\")\n",
    "    \n",
    "for i in range(c0_train, c0):\n",
    "    file = \"driver/c0/\" + c0_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c0\")\n",
    "'''    \n",
    "\n",
    "\n",
    "for i in range(0, c1_train):\n",
    "    file = \"driver/c1/\" + c1_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c1\")\n",
    "    \n",
    "for i in range(c1_train, c1):\n",
    "    file = \"driver/c1/\" + c1_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c1\")\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(0, c2_train):\n",
    "    file = \"driver/c2/\" + c2_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c2\")\n",
    "    \n",
    "for i in range(c2_train, c2):\n",
    "    file = \"driver/c2/\" + c2_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c2\")\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(0, c3_train):\n",
    "    file = \"driver/c3/\" + c3_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c3\")\n",
    "    \n",
    "for i in range(c3_train, c3):\n",
    "    file = \"driver/c3/\" + c3_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c3\")\n",
    "    \n",
    "    \n",
    "for i in range(0, c4_train):\n",
    "    file = \"driver/c4/\" + c4_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c4\")\n",
    "    \n",
    "for i in range(c4_train, c4):\n",
    "    file = \"driver/c4/\" + c4_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c4\")\n",
    "    \n",
    "    \n",
    "for i in range(0, c5_train):\n",
    "    file = \"driver/c5/\" + c5_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c5\")\n",
    "    \n",
    "for i in range(c5_train, c5):\n",
    "    file = \"driver/c5/\" + c5_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c5\")\n",
    "    \n",
    "    \n",
    "for i in range(0, c6_train):\n",
    "    file = \"driver/c6/\" + c6_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c6\")\n",
    "    \n",
    "for i in range(c6_train, c6):\n",
    "    file = \"driver/c6/\" + c6_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c6\")\n",
    "    \n",
    "    \n",
    "for i in range(0, c7_train):\n",
    "    file = \"driver/c7/\" + c7_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c7\")\n",
    "    \n",
    "for i in range(c7_train, c7):\n",
    "    file = \"driver/c7/\" + c7_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c7\")\n",
    "    \n",
    "\n",
    "for i in range(0, c8_train):\n",
    "    file = \"driver/c8/\" + c8_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c8\")\n",
    "    \n",
    "for i in range(c8_train, c8):\n",
    "    file = \"driver/c8/\" + c8_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c8\")\n",
    "    \n",
    "\n",
    "for i in range(0, c9_train):\n",
    "    file = \"driver/c9/\" + c9_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/train/c9\")\n",
    "    \n",
    "for i in range(c9_train, c9):\n",
    "    file = \"driver/c9/\" + c9_files[i]\n",
    "    shutil.move(file, \"driver_data_prepared/test/c9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, \\\n",
    "                                       ZeroPadding2D\n",
    "\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "# from sklearn.metrics import log_loss\n",
    "from numpy.random import permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (Can't locate attribute: 'layer_names')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa7fe3815766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vgg16_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Code above loads pre-trained data and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m    735\u001b[0m                                                           skip_mismatch=skip_mismatch)\n\u001b[0;32m    736\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m             \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3125\u001b[0m             \u001b[0mfiltered_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3127\u001b[1;33m     \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3128\u001b[0m     \u001b[0mfiltered_layer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[0;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Can't open attribute (Can't locate attribute: 'layer_names')\""
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(300, 300, 3)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "model.load_weights('vgg16_weights.h5')\n",
    "\n",
    "# Code above loads pre-trained data and\n",
    "model.layers.pop()\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Learning rate is changed to 0.001\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Old codes\n",
    "#classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            shuffle=True)\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 20,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)\n",
    "\n",
    "print(\"CNN Network Trained\")\n",
    "classifier.save('distracted_driving.h5')\n",
    "del classifier\n",
    "print(\"CNN Network Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
